<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Pregel+</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Add custom CSS here -->
    <style>
    body {
        margin-top: 60px;
    }
    </style>

</head>

<body>

    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Pregel+</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <li><a href="introduction.html">Introduction</a>
					</li>
					<li><a href="download.html">Download</a>
					</li>
					<li><a href="documentation.html">Documentation</a>
					</li>
					<li><a href="publications.html">Publications</a>
					</li>
					<li><a href="team.html">Team</a>
					</li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <div class="container">

        <div class="row">
            <div class="col-lg-12">
                <h1>Deploy Hadoop on Ubuntu Linux (Multi-Node Cluster)</h1>
                <h3>Configuring SSH</h3>
                <p>Hadoop requires SSH access to manage its nodes, we therefore need to configure SSH access to your local machine plus remote machines. </p>
                <div class="alert alert-info">
                    <p>sudo apt-get install ssh</p>
                </div>
                <p>For the sake of illustration, in this tutorial, we assume you have a linux user named <strong>hadoop</strong> in the <strong>hadoop</strong> group, your local machine's hostname is <strong>master</strong> and your remote machines' hostnames are from <strong>slave1</strong> to <strong>slaveN</strong>. </p>
                
                <p>Now, let's create an RSA key pair with an empty password. Then, we have to enable SSH access to the local machine plus remote machines with this newly created key.</p>
                <div class="alert alert-info">
                    <p>ssh-keygen -t rsa</p>
                    <p>cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys</p>
                    <p>cat .ssh/id_rsa.pub | ssh hadoop@slave1 'cat >> .ssh/authorized_keys'</p>
                    <p>...</p>
                    <p>cat .ssh/id_rsa.pub | ssh hadoop@slaveN 'cat >> .ssh/authorized_keys'</p>
                </div>
                <h3>OpenJDK 7 (all machines)</h3>
                <p>Hadoop requires a working Java 1.5+ (aka Java 5) installation. However, using Java 1.7 (aka Java 7) is recommended for running Hadoop. I will therefore describe the installation of Java 1.7.</p>
                <div class="alert alert-info">
                    <p>sudo apt-get install openjdk-7-jdk</p>
                </div>
                <h3>Hadoop (all machines)</h3>
                <p>Download Hadoop 1.2.1 from the <a href="http://hadoop.apache.org/releases.html">Apache</a> and extract the contents of the Hadoop package to a location of your choice. I picked <strong>/usr/local/hadoop</strong>. Make sure to change the owner of all the files to the <strong>hadoop</strong> user and <strong>hadoop</strong> group, for example:</p>
                <div class="alert alert-info">
                    <p>cd /usr/local</p>
                    <p>sudo tar xzvf hadoop-1.2.1.tar.gz</p>
                    <p>sudo mv hadoop-1.2.1 hadoop</p>
                    <p>sudo chown -R hadoop:hadoop hadoop</p>
                </div>
                <h3>Update $HOME/.bashrc (all machines)</h3>
                <p>Add the following lines to the end of the <strong>$HOME/.bashrc</strong> file of user <strong>hadoop</strong>.</p>
                <div class="alert alert-info">
                    <p>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64</p>
                    <p>export HADOOP_HOME=/usr/local/hadoop</p>
                    <p>export PATH=$PATH:$HADOOP_HOME/bin</p>
                </div>
                <div class="alert alert-info">
                    <p>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_HOME/jre/lib/amd64/server</p>
                    <p>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/c++/Linux-amd64-64/lib</p>
                </div>
                <div class="alert alert-info">
                    <p>for i in $HADOOP_HOME/*.jar</p>
                    <p>do</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;CLASSPATH=$CLASSPATH:$i</p>
                    <p>done</p>

                    <p>for i in $HADOOP_HOME/lib/*.jar</p>
                    <p>do</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;CLASSPATH=$CLASSPATH:$i</p>
                    <p>done</p>
                    
                    <p>export CLASSPATH</p>
                </div>
                
                <h3>Configure Hadoop (master only)</h3>
                <p>Update <strong>conf/masters</strong> that it looks like this:</p>
                <div class="alert alert-info">
                    <p>master</p>
                </div>
                <p>Update <strong>conf/slaves</strong> that it looks like this:</p>
                <div class="alert alert-info">
                    <p>slave1</p>
                    <p>...</p>
                    <p>slaveN</p>
                </div>
                
                <h3>Configure Hadoop (all machines)</h3>
                <p>Open <strong>conf/hadoop-env.sh</strong> and set the <strong>JAVA_HOME</strong> environment variable to the Sun JDK/JRE 7 directory.</p>
                <div class="alert alert-info">
                    <p>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64</p>
                </div>
                <p>Now, we create the directory where Hadoop will store its data files and set the required ownerships and permissions.</p>
                <div class="alert alert-info">
                    <p>sudo chown hadoop:hadoop /app/hadoop/tmp</p>
                    <p>sudo mkdir -p /app/hadoop/tmp</p>
                    <p>sudo chmod 755 /app/hadoop/tmp</p>
                </div>
                <p>In file <strong>conf/core-site.xml</strong></p>
                <div class="alert alert-info">
                
                    <p>&lt;property&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;/app/hadoop/tmp&lt;/value&gt;</p>
                    <p>&lt;/property&gt;</p>

                    <p>&lt;property&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;fs.default.name&lt;/name&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;hdfs://master:9000&lt;/value&gt;</p>
                    <p>&lt;/property&gt;</p>
                </div>
                <p>In file <strong>conf/mapred-site.xml</strong></p>
                <div class="alert alert-info">
                    <p>&lt;property&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;mapred.job.tracker&lt;/name&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;hdfs://master:9001&lt;/value&gt;</p>
                    <p>&lt;/property&gt;</p>
                </div>
                <p>In file <strong>conf/hdfs-site.xml</strong></p>
                <div class="alert alert-info">
                    <p>&lt;property&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;dfs.replication&lt;/name&gt;</p>
                    <p>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;3&gt;</p>
                    <p>&lt;/property&gt;</p>
                </div>
                <h3>Formatting the HDFS filesystem via the NameNode (master only)</h3>
                <p>Before we start our new multi-node cluster, we must format Hadoopâ€™s distributed filesystem (HDFS) via the NameNode. You need to do this the first time you set up an Hadoop cluster.</p>
                <div class="alert alert-danger">
                Warning: Do not format a running cluster because this will erase all existing data in the HDFS filesytem!
                </div>
                <p>To format the filesystem, run the command</p>
                <div class="alert alert-info">
                    <p>/usr/local/hadoop/bin/hadoop namenode -format</p>
                </div>
                <h3>Start your cluster (master only)</h3>
                <p>Run the command</p>
                <div class="alert alert-info">
                    <p>/usr/local/hadoop/bin/start-all.sh</p>
                </div>
                <p>A nifty tool for checking whether the expected Hadoop processes are running is <strong>jps</strong>.  (part of openJDK)</p>
                <div class="alert alert-info">
                    <p>jps</p>
                </div>
                <p>The output will look like this:</p>
                <div class="alert alert-warning">
                    <p>19454 Jps</p>
                    <p>2955 NameNode</p>
                    <p>3258 JobTracker</p>
                    <p>3169 SecondaryNameNode</p>
                </div>
                <h3>Stop your single-node cluster (master only)</h3>
                <p>If you want to do so, then run the command</p>
                <div class="alert alert-info">
                    <p>/usr/local/hadoop/bin/stop-all.sh</p>
                </div>
            </div>
            
        </div>

    </div>
    <!-- /.container -->

    <!-- JavaScript -->
    <script src="js/jquery-1.10.2.js"></script>
    <script src="js/bootstrap.js"></script>

</body>

</html>
